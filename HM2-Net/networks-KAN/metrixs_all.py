import os
import numpy as np
from PIL import Image
from scipy.spatial.distance import cdist
from skimage.transform import resize

# è®¾å®šé¢„æµ‹ç»“æœçš„å›ºå®šå°ºå¯¸
PREDICTION_SIZE = (224, 224)


def load_png_files(folder_path, resize_shape=None):
    """ åŠ è½½ PNG å›¾åƒï¼Œå¹¶è¿”å›å­—å…¸ {æ–‡ä»¶å: å›¾åƒæ•°ç»„}ï¼Œå¯é€‰ resize å¤„ç† """
    data = {}
    if not os.path.exists(folder_path):
        print(f"âš ï¸  æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return data
    for filename in os.listdir(folder_path):
        if filename.endswith('.png'):
            file_path = os.path.join(folder_path, filename)
            image = np.array(Image.open(file_path).convert('L'))  # è½¬ä¸ºç°åº¦å›¾

            # ç»Ÿä¸€ resize labels
            if resize_shape:
                image = resize(image, resize_shape, order=0, preserve_range=True, anti_aliasing=False).astype(np.uint8)

            data[filename] = image
    return data


def binarize_image(image):
    """ äºŒå€¼åŒ–å›¾åƒ """
    return (image > 0).astype(np.uint8)


def hausdorff_distance(A, B, max_dist=100):
    """ è®¡ç®— Hausdorff 95 è·ç¦»ï¼Œå¤„ç†ç©ºé›†æƒ…å†µï¼Œé¿å… inf"""
    A_points = np.argwhere(A)
    B_points = np.argwhere(B)

    if len(A_points) == 0 or len(B_points) == 0:
        return max_dist  # å¦‚æœé¢„æµ‹æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œåˆ™è¿”å›å›ºå®šçš„å¤§å€¼

    d_matrix = cdist(A_points, B_points)
    return np.percentile(d_matrix, 95)  # è®¡ç®— 95% Hausdorff è·ç¦»


def calculate_metrics(predictions, labels, num_classes=2):
    """ è®¡ç®—åˆ†å‰²æŒ‡æ ‡ï¼ˆDice, IoU, Recall, Precision, Hausdorffï¼‰"""
    metrics = {"Dice": [], "IoU": [], "Recall": [], "Precision": [], "Hausdorff": []}

    for cls in range(1, num_classes):  # å¿½ç•¥èƒŒæ™¯ï¼ˆclass 0ï¼‰
        cls_preds = (predictions == cls).astype(int)
        cls_labels = (labels == cls).astype(int)

        intersection = np.sum(cls_preds * cls_labels)
        dice = (2. * intersection) / (np.sum(cls_preds) + np.sum(cls_labels) + 1e-6)
        metrics["Dice"].append(dice)

        union = np.sum(cls_preds) + np.sum(cls_labels) - intersection
        iou = intersection / (union + 1e-6)
        metrics["IoU"].append(iou)

        recall = intersection / (np.sum(cls_labels) + 1e-6)
        precision = intersection / (np.sum(cls_preds) + np.sum(cls_labels) + 1e-6)
        metrics["Recall"].append(recall)
        metrics["Precision"].append(precision)

        # è®¡ç®— Hausdorff 95 è·ç¦»
        hausdorff = hausdorff_distance(cls_preds, cls_labels)

        if hausdorff == 100:  # ä¹‹å‰çš„ inf ç°åœ¨å˜æˆ 100
            print(f"âš ï¸ Hausdorff è®¡ç®—å¼‚å¸¸: é¢„æµ‹æˆ–æ ‡ç­¾ä¸ºç©ºï¼Œè¿”å› {hausdorff}")

        metrics["Hausdorff"].append(hausdorff)

    return {key: np.mean(value) for key, value in metrics.items()}  # è®¡ç®—å‡å€¼


def evaluate_best_model(predictions_root, label_folder, output_file, best_model_folder, num_classes=2):
    """ è¯„ä¼°æŒ‡å®šçš„æœ€ä½³æ¨¡å‹çš„æ¨ç†ç»“æœ """

    prediction_folder = os.path.join(predictions_root, best_model_folder)

    if not os.path.exists(prediction_folder):
        print(f"âš ï¸ é¢„æµ‹ç»“æœæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {prediction_folder}ï¼Œè·³è¿‡...")
        return

    predictions = load_png_files(prediction_folder)  # é¢„æµ‹ç»“æœä¸éœ€è¦ resize
    labels = load_png_files(label_folder, resize_shape=PREDICTION_SIZE)  # ç»Ÿä¸€ resize labels

    common_files = set(predictions.keys()) & set(labels.keys())
    if not common_files:
        print(f"âš ï¸  {best_model_folder} æ— åŒ¹é…çš„é¢„æµ‹å’Œæ ‡ç­¾æ–‡ä»¶ï¼Œè·³è¿‡...")
        return

    print(f"ğŸ“Š æ­£åœ¨è®¡ç®— {best_model_folder} çš„æŒ‡æ ‡...")

    overall_metrics = {"Dice": [], "IoU": [], "Recall": [], "Precision": [], "Hausdorff": []}

    for filename in common_files:
        pred = binarize_image(predictions[filename])
        label = binarize_image(labels[filename])

        metrics = calculate_metrics(pred, label, num_classes)

        for key in overall_metrics.keys():
            overall_metrics[key].append(metrics[key])

    # è®¡ç®—è¯¥æ¨¡å‹çš„æ€»ä½“å‡å€¼
    avg_metrics = {key: np.mean(value) for key, value in overall_metrics.items()}

    # å†™å…¥æ—¥å¿—
    with open(output_file, 'w') as f:
        f.write(f"\nModel: {best_model_folder}\n")
        for key, value in avg_metrics.items():
            f.write(f"{key}: {value:.4f}\n")

    print(f"âœ… {best_model_folder} è®¡ç®—å®Œæˆï¼")
    print(f"ğŸ“Œ è¯„ä¼°å®Œæˆï¼Œç»“æœå·²ä¿å­˜è‡³ {output_file}")


if __name__ == "__main__":
    # ä½ çš„å¤šä¸ªæ•°æ®é›†çš„è·¯å¾„ï¼Œæ ¼å¼ä¸º (é¢„æµ‹ç»“æœè·¯å¾„, æ ‡ç­¾è·¯å¾„, ç»“æœæ–‡ä»¶è·¯å¾„)
    datasets = [
        ("/home/shuoxing/data/TransUNet/Results/KAT-1/CVC-300",
         "/home/shuoxing/data/TransUNet/dataset/TestDataset/CVC-300/masks",
         "/home/shuoxing/data/TransUNet/Results/KAT-1/TxT/all_results_CVC-300.txt"),

        ("/home/shuoxing/data/TransUNet/Results/KAT-1/CVC-ClinicDB",
         "/home/shuoxing/data/TransUNet/dataset/TestDataset/CVC-ClinicDB/masks",
         "/home/shuoxing/data/TransUNet/Results/KAT-1/TxT/all_results_ClinicDB.txt"),

        ("/home/shuoxing/data/TransUNet/Results/KAT-1/CVC-ColonDB",
         "/home/shuoxing/data/TransUNet/dataset/TestDataset/CVC-ColonDB/masks",
         "/home/shuoxing/data/TransUNet/Results/KAT-1/TxT/all_results_CVC-ColonDB.txt"),

        ("/home/shuoxing/data/TransUNet/Results/KAT-1/ETIS",
         "/home/shuoxing/data/TransUNet/dataset/TestDataset/ETIS-LaribPolypDB/masks",
         "/home/shuoxing/data/TransUNet/Results/KAT-1/TxT/all_results_ETIS.txt"),

        ("/home/shuoxing/data/TransUNet/Results/KAT-1/Kvasir",
         "/home/shuoxing/data/TransUNet/dataset/TestDataset/Kvasir/masks",
         "/home/shuoxing/data/TransUNet/Results/KAT-1/TxT/all_results_Kvasir.txt"),
    ]

    best_model_folder = "KAT-best"  # æŒ‡å®šæœ€ä½³æ¨¡å‹æ–‡ä»¶å¤¹

    for pred_path, label_path, output_file in datasets:
        print(f"\nğŸ” å¼€å§‹è¯„ä¼°æœ€ä½³æ¨¡å‹: {pred_path}")
        evaluate_best_model(pred_path, label_path, output_file, best_model_folder, num_classes=2)
